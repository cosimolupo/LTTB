{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Through Target Bursts (LTTB) - Figure 2\n",
    "\n",
    "This notebook reproduces the results presented in `Figure 2` of the <a href=\"https://arxiv.org/abs/2201.11717\">arXiv 2201.11717</a> preprint paper: Cristiano Capone<sup>\\*</sup>, Cosimo Lupo<sup>\\*</sup>, Paolo Muratore, Pier Stanislao Paolucci (2022) \"*Burst-dependent plasticity and dendritic amplification support target-based learning and hierarchical imitation learning*\". We test the `LTTB` model on a 3D-trajectory task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please give credit to this paper if you use or modify the code in a derivative work. This work is licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Import & Parameter Loading\n",
    "\n",
    "In this section we import the needed external libraries and load the model parameters for this task (via the `json` configuration file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import lttb as lttb_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./config.json', 'r') as fp:\n",
    "    par = json.load(fp)['FIGURE_2']\n",
    "\n",
    "n_contexts = par['n_contexts']\n",
    "T = par['T']\n",
    "dt = par['dt']\n",
    "tau_m = par['tau_m']\n",
    "eta = par['eta']\n",
    "eta_out = par['eta_out']\n",
    "\n",
    "Ne = par['Ne']\n",
    "Ni = par['Ni']\n",
    "\n",
    "gamma = 1./par['du']\n",
    "def f(x,gamma):\n",
    "    return np.exp(x*gamma)/(np.exp(x*gamma)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions\n",
    "\n",
    "In this section we define several useful functions that will be used during the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# * Define clock and target\n",
    "def init_clock_targ():\n",
    "    \n",
    "    lttb.y_targ_collection = []\n",
    "    \n",
    "    for k in range(n_contexts):\n",
    "        lttb.init_targ(par)\n",
    "        lttb.y_targ_collection.append(lttb.y_targ)\n",
    "    \n",
    "    \n",
    "    lttb.init_clock(par)\n",
    "\n",
    "# * Sparsify target and context projections\n",
    "def sparsify_targ(p):\n",
    "    # p is the fraction of masked elements\n",
    "    mask = np.array([0. if random.random()<p else 1. for _ in range(lttb.N*lttb.O)]).reshape((lttb.N,lttb.O))\n",
    "    lttb.j_targ = lttb.j_targ*mask\n",
    "    return\n",
    "\n",
    "def sparsify_cont(p):\n",
    "    # p is the fraction of masked elements\n",
    "    mask = np.array([0. if random.random()<p else 1. for _ in range(lttb.N*lttb.n_contexts)]).reshape((lttb.N,lttb.n_contexts))\n",
    "    lttb.j_apical_cont = lttb.j_apical_cont*mask\n",
    "    mask = np.array([0. if random.random()<p else 1. for _ in range(lttb.N*lttb.n_contexts)]).reshape((lttb.N,lttb.n_contexts))\n",
    "    lttb.j_basal_cont = lttb.j_basal_cont*mask\n",
    "    return\n",
    "\n",
    "# * -------------- TESTING FUNCTIONS --------------------\n",
    "def short_test():\n",
    "    \n",
    "    mses = np.zeros(n_contexts)\n",
    "    \n",
    "    for cont_index in range(n_contexts):\n",
    "    \n",
    "        lttb.cont = lttb.cont*0\n",
    "        lttb.cont[cont_index] = 1\n",
    "        lttb.y_targ = lttb.y_targ_collection[cont_index]\n",
    "        lttb.initialize(par)\n",
    "    \n",
    "        #run simulation\n",
    "        for t in range(lttb.T-2):\n",
    "            lttb.step(apicalFactor = 0)\n",
    "\n",
    "        SR = lttb.B_filt_rec[:,1:-2]\n",
    "        Y = lttb.Jout@SR + np.tile(lttb.Bias,(lttb.T-3,1)).T\n",
    "        mse_rec_train = np.std(lttb.y_targ[:,1:-2] - Y)**2\n",
    "        mses[cont_index] = mse_rec_train\n",
    "    \n",
    "    return mses\n",
    "\n",
    "def full_test():\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    stats['targs'] = []\n",
    "    stats['outputs'] = []\n",
    "    stats['contexts'] = []\n",
    "    stats['S_somas'] = []\n",
    "    stats['S_winds'] = []\n",
    "    stats['mses'] = np.zeros(n_contexts)\n",
    "    if n_contexts==2:\n",
    "        stats['mses_offDiag'] = np.zeros(n_contexts)\n",
    "    \n",
    "    for cont_index in range(n_contexts):\n",
    "        \n",
    "        context = np.zeros((lttb.T-2,n_contexts))\n",
    "        context[:,cont_index] = np.array([1 for _ in range(lttb.T-2)])\n",
    "        lttb.y_targ = lttb.y_targ_collection[cont_index]\n",
    "        lttb.initialize(par)\n",
    "\n",
    "        #run simulation\n",
    "        for t in range(lttb.T-2):\n",
    "            lttb.cont = context[t]\n",
    "            lttb.step(apicalFactor = 0)\n",
    "\n",
    "        SR = lttb.B_filt_rec[:,1:-2]\n",
    "        Y = lttb.Jout@SR + np.tile(lttb.Bias,(lttb.T-3,1)).T\n",
    "        \n",
    "        stats['outputs'].append(Y)\n",
    "        stats['contexts'].append(context)\n",
    "        stats['S_somas'].append(lttb.S_soma)\n",
    "        stats['S_winds'].append(lttb.S_wind)\n",
    "        stats['targs'].append(lttb.y_targ[:,1:-2])\n",
    "        stats['mses'][cont_index] = np.std(lttb.y_targ[:,1:-2] - Y)**2\n",
    "        if n_contexts==2:\n",
    "            wrong_targ = lttb.y_targ_collection[1-cont_index][:,1:-2]\n",
    "            stats['mses_offDiag'][cont_index] = np.std(wrong_targ - Y)**2\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# * --------------------- TRAINING FUNCTION --------------------------------\n",
    "def training(nIterRec=100, test_every=5, eta=5., eta_out=0.01, etaW=0., eta_bias=0.0002, verbose = True):\n",
    "    \n",
    "    ERRORS = np.zeros((int(nIterRec/test_every),n_contexts))\n",
    "    \n",
    "    iterator = trange(nIterRec, desc = 'LTTB Training', leave = True)\n",
    "\n",
    "    for iteration in iterator:\n",
    "    \n",
    "        #initialize simulation\n",
    "        \n",
    "        for cont_index in range(n_contexts):\n",
    "        \n",
    "            lttb.cont = lttb.cont*0\n",
    "            lttb.cont[cont_index] = 1\n",
    "            lttb.y_targ = lttb.y_targ_collection[cont_index]\n",
    "            lttb.initialize(par)\n",
    "    \n",
    "            #run simulation\n",
    "            dH = 0\n",
    "            for t in range(lttb.T-2):\n",
    "                lttb.step(apicalFactor = 1)\n",
    "    \n",
    "                dH = dH*(1-dt/tau_m) + dt/tau_m*lttb.S_filt[:,t]\n",
    "                DJ = np.outer( ( lttb.S_apic_dist[:,t+1] - f(lttb.VapicRec[:,t],gamma) )*(1-lttb.S_apic_prox[:,t])*lttb.S_wind_soma[:,t+1] ,dH)\n",
    "                lttb.J =  lttb.J + eta*DJ\n",
    "    \n",
    "                SR = lttb.B_filt_rec[:,t+1]\n",
    "                Y = lttb.Jout@SR + lttb.Bias\n",
    "                DJRO = np.outer(lttb.y_targ[:,t+1] - Y,SR.T)\n",
    "                dBias = lttb.y_targ[:,t+1] - Y\n",
    "                lttb.Jout = lttb.Jout + eta_out*DJRO\n",
    "                lttb.Bias = lttb.Bias + eta_bias*dBias\n",
    "        \n",
    "        ###### Test\n",
    "        \n",
    "        if (iteration+1)%test_every==0:\n",
    "            \n",
    "            mses = short_test()\n",
    "            \n",
    "            ERRORS[int(iteration/test_every),:] = mses\n",
    "            \n",
    "            if verbose:\n",
    "                msg = 'LTTB Training. MSEs: ' + ''.join([f'{mse:.4f} | ' for mse in mses])\n",
    "                iterator.set_description(msg)\n",
    "\n",
    "    return ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### More sophisticated tests about context\n",
    "def context_test(test_type, t_sw):\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    dt_sw = 100\n",
    "    \n",
    "    if test_type not in ['turnoff']:\n",
    "        print('ERROR: Not allowed test for context. Only \\'turnoff\\' is allowed.')\n",
    "        return stats\n",
    "    \n",
    "    print('Context experiment=\\'%s\\', t_sw=%d' % (test_type,t_sw))\n",
    "    \n",
    "    stats['targs'] = []\n",
    "    stats['outputs'] = []\n",
    "    stats['contexts'] = []\n",
    "    stats['S_somas'] = []\n",
    "    stats['S_winds'] = []\n",
    "    \n",
    "    if test_type=='turnoff':\n",
    "        stats['mses_before_onDiag'] = []\n",
    "        stats['mses_before_offDiag'] = []\n",
    "        stats['mses_after_onDiag'] = []\n",
    "        stats['mses_after_offDiag'] = []\n",
    "    \n",
    "    for cont_index in range(n_contexts):\n",
    "        context = np.zeros((lttb.T-2,n_contexts))\n",
    "        \n",
    "        if test_type=='turnoff':\n",
    "            context[:,cont_index] = np.array([1 if _<=t_sw else 0 for _ in range(lttb.T-2)])\n",
    "\n",
    "        lttb.y_targ = lttb.y_targ_collection[cont_index]\n",
    "        lttb.initialize(par)\n",
    "\n",
    "        #run simulation\n",
    "        for t in range(lttb.T-2):\n",
    "            lttb.cont = context[t]\n",
    "            lttb.step(apicalFactor = 0)\n",
    "\n",
    "        SR = lttb.B_filt_rec[:,1:-2]\n",
    "        Y = lttb.Jout@SR + np.tile(lttb.Bias,(lttb.T-3,1)).T\n",
    "        \n",
    "        stats['outputs'].append(Y)\n",
    "        stats['contexts'].append(context)\n",
    "        stats['S_somas'].append(lttb.S_soma)\n",
    "        stats['S_winds'].append(lttb.S_wind)\n",
    "        \n",
    "        right_targ = lttb.y_targ_collection[cont_index][:,1:-2]\n",
    "        \n",
    "        if test_type=='turnoff':\n",
    "            right_targ = lttb.y_targ_collection[cont_index][:,1:t_sw+1]\n",
    "            right_targ = np.append(right_targ, lttb.y_targ_collection[cont_index][:,t_sw+1:-2], 1)\n",
    "            mse_rec_train_before_onDiag = np.std(lttb.y_targ_collection[cont_index][:,1:t_sw+1-dt_sw] - Y[:,0:t_sw-dt_sw])**2\n",
    "            mse_rec_train_after_onDiag = np.std(lttb.y_targ_collection[cont_index][:,t_sw+1+dt_sw:-2] - Y[:,t_sw+dt_sw:])**2\n",
    "            if n_contexts==2:\n",
    "                wrong_targ = lttb.y_targ_collection[1-cont_index][:,1:t_sw+1]\n",
    "                wrong_targ = np.append(wrong_targ, lttb.y_targ_collection[1-cont_index][:,t_sw+1:-2], 1)\n",
    "                mse_rec_train_before_offDiag = np.std(lttb.y_targ_collection[1-cont_index][:,1:t_sw+1-dt_sw] - Y[:,0:t_sw-dt_sw])**2\n",
    "                mse_rec_train_after_offDiag = np.std(lttb.y_targ_collection[1-cont_index][:,t_sw+1+dt_sw:-2] - Y[:,t_sw+dt_sw:])**2\n",
    "        \n",
    "        stats['targs'].append(right_targ)\n",
    "        \n",
    "        if test_type=='turnoff':\n",
    "            stats['mses_before_onDiag'].append(mse_rec_train_before_onDiag)\n",
    "            stats['mses_after_onDiag'].append(mse_rec_train_after_onDiag)\n",
    "            if n_contexts==2:\n",
    "                stats['mses_before_offDiag'].append(mse_rec_train_before_offDiag)\n",
    "                stats['mses_after_offDiag'].append(mse_rec_train_after_offDiag)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lttb = lttb_module.LTTB(par)\n",
    "init_clock_targ()\n",
    "\n",
    "n_session = 1\n",
    "\n",
    "ERRORS = []\n",
    "eta = par['eta']\n",
    "eta_out = par['eta_out']\n",
    "rescale_eta = True\n",
    "factor_eta = 0.5\n",
    "nEpochs = 5\n",
    "nIterRec = 100\n",
    "\n",
    "sparsify_cont = True\n",
    "\n",
    "if sparsify_cont:\n",
    "    sparsify_targ(par['p_sparse_cont'])\n",
    "    sparsify_cont(par['p_sparse_cont'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "In this section we train the model via the `training` function on the `3D Trajectory` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(nEpochs):\n",
    "    ERRORS.extend( training(nIterRec=nIterRec, eta=eta, eta_out=eta_out, eta_bias=0, verbose = True) )\n",
    "    if rescale_eta:\n",
    "        eta *= factor_eta\n",
    "        eta_out *= factor_eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Test: Context Turnoff\n",
    "\n",
    "In this section we perform a different test on the trained model: we probe the effect of turning off the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the context test\n",
    "res = context_test(test_type='turnoff', t_sw=500)\n",
    "\n",
    "# Format the results\n",
    "cont_index = 0\n",
    "\n",
    "contexts = res['contexts']\n",
    "context = contexts[cont_index]\n",
    "Y = res['outputs'][cont_index]\n",
    "targ = res['targs'][cont_index]\n",
    "S_soma = res['S_somas'][cont_index]\n",
    "S_wind = res['S_winds'][cont_index]\n",
    "\n",
    "M1 = [S_soma[i][j] if S_wind[i][j]==0 else 0 for i in range(len(S_soma)) for j in range(len(S_soma[i]))]\n",
    "M2 = [S_soma[i][j] if S_wind[i][j]>0 else 0 for i in range(len(S_soma)) for j in range(len(S_soma[i]))]\n",
    "M1 = np.array(M1).reshape(np.shape(S_soma))\n",
    "M2 = np.array(M2).reshape(np.shape(S_soma))\n",
    "\n",
    "v1 = []\n",
    "v2 = []\n",
    "for i in range(np.shape(S_soma)[0]):\n",
    "    for j in range(np.shape(S_soma)[1]):\n",
    "        if(M1[i][j]>0):\n",
    "            v1.append(i)\n",
    "            v2.append(j)\n",
    "\n",
    "w1 = []\n",
    "w2 = []\n",
    "for i in range(np.shape(S_soma)[0]):\n",
    "    for j in range(np.shape(S_soma)[1]):\n",
    "        if(M2[i][j]>0):\n",
    "            w1.append(i)\n",
    "            w2.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {}\n",
    "dct['target'] = lttb.y_targ_collection\n",
    "dct['output'] = res['outputs']\n",
    "for i,ii in enumerate(dct['target']):\n",
    "    dct['target'][i] = [_ for _ in dct['target'][i]]\n",
    "    for j,jj in enumerate(dct['target'][i]):\n",
    "        dct['target'][i][j] = [round(_,8) for _ in dct['target'][i][j]]\n",
    "for i,ii in enumerate(dct['output']):\n",
    "    dct['output'][i] = [_ for _ in dct['output'][i]]\n",
    "    for j,jj in enumerate(dct['output'][i]):\n",
    "        dct['output'][i][j] = [round(_,8) for _ in dct['output'][i][j]]\n",
    "dct['eta'] = par['eta']\n",
    "dct['eta_out'] = par['eta_out']\n",
    "dct['N_epochs'] = nEpochs\n",
    "dct['N_iterEpoch'] = nIterRec\n",
    "dct['test_every'] = test_every\n",
    "dct['rescale_eta'] = rescale_eta\n",
    "dct['factor_eta'] = factor_eta\n",
    "dct['sparsify_cont'] = sparsify_cont\n",
    "dct['p_sparse_cont'] = par['p_sparse_cont']\n",
    "dct['mse_during_training'] = [round(l[0],8) for l in ERRORS]\n",
    "with open ('./data/Fig_2/Results_figure2_n%03d.json' % n_session, 'w') as fp:\n",
    "    json.dump(dct, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Visualization\n",
    "\n",
    "Here we visualize the results for the context turnoff test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 12\n",
    "cm = 1/2.54  # centimeters in inches\n",
    "final_dpi = 500\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12*cm, 12*cm))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fs, pad=1)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    ax.xaxis.set_tick_params(width=0.5)\n",
    "    ax.yaxis.set_tick_params(width=0.5)\n",
    "\n",
    "ax = axes[0]\n",
    "for d in range(n_contexts):\n",
    "    ax.plot(context.T[d], zorder=1, ls='--', color=['black','red'][d], lw=1, alpha=0.5)\n",
    "ax.set_ylabel('', fontsize=fs)\n",
    "ax.set_xlim([0,1000])\n",
    "ax.text(-0.15, 0.5, 'context', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "        transform=ax.transAxes, rotation_mode='anchor')\n",
    "    \n",
    "ax = axes[1]\n",
    "for d in range(1):\n",
    "    ax.plot(np.array(Y)[d].T, zorder=0, color='C' + str(d+1), lw=2)\n",
    "for d in range(1):\n",
    "    ax.plot(np.array(targ)[d].T, zorder=1, ls='--', color='C' + str(d+1), lw=1)\n",
    "ax.set_ylabel('', fontsize=fs)\n",
    "ax.set_xlim([0,1000])\n",
    "ax.text(-0.15, 0.5, 'trajectories', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "        transform=ax.transAxes, rotation_mode='anchor')\n",
    "\n",
    "ax = axes[2]\n",
    "cmap1 = matplotlib.colors.ListedColormap(['None','orange'], name='colors', N=None)\n",
    "cmap2 = matplotlib.colors.ListedColormap(['None','blue'], name='colors', N=None)\n",
    "for i in range(len(v1)):\n",
    "    if(v1[i]>2 and v1[i]<99 and v2[i]>2 and v2[i]<999):\n",
    "        y = v1[i]\n",
    "        ax.scatter(v2[i], y, color='orange', marker='.', s=2)\n",
    "for i in range(len(w1)):\n",
    "    if(w1[i]>1 and w1[i]<100 and w2[i]>2 and w2[i]<999):\n",
    "        y = w1[i]\n",
    "        ax.scatter(w2[i], y, color='blue', marker='.', s=2)\n",
    "ax.set_xlabel('t', fontsize=fs)\n",
    "ax.set_ylabel('', fontsize=fs)\n",
    "ax.set_xlim([0,1000])\n",
    "ax.set_ylim([100,0])\n",
    "ax.set_xticks([0,500,1000])\n",
    "ax.set_yticks([100,50,0])\n",
    "ax.text(-0.15, 0.5, 'neuron id', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "        transform=ax.transAxes, rotation_mode='anchor')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.23, bottom=0.12, right=0.93, top=0.95, wspace=None, hspace=0.4)\n",
    "fig_title = 'figure2_n%03d' % n_session\n",
    "for ext in ['eps','pdf','png']:\n",
    "    plt.savefig('./figures/Fig_2/' + fig_title + '.' + ext, dpi=final_dpi)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63bc7039520e9c83d9945330fac7eb95e94f586fea51b2481b3811e9cf2146ad"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
