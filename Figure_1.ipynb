{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aaa2d41",
   "metadata": {},
   "source": [
    "# Learning Through Target Bursts (LTTB) - Figure 1\n",
    "\n",
    "This notebook reproduces the results presented in `Figure 1` of the <a href=\"https://arxiv.org/abs/2201.11717\">arXiv 2201.11717</a> preprint paper: Cristiano Capone<sup>\\*</sup>, Cosimo Lupo<sup>\\*</sup>, Paolo Muratore, Pier Stanislao Paolucci (2022) \"*Burst-dependent plasticity and dendritic amplification support target-based learning and hierarchical imitation learning*\". We test the `LTTB` model on a 3D-trajectory task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1ba59",
   "metadata": {},
   "source": [
    "Please give credit to this paper if you use or modify the code in a derivative work. This work is licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290e204",
   "metadata": {},
   "source": [
    "### Libraries Import\n",
    "\n",
    "In this section we import the needed external libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a8a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "import lttb as lttb_module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237a42a",
   "metadata": {},
   "source": [
    "### Function Definitions\n",
    "\n",
    "In this section we define several useful functions that will be used during the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f790b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(x,gamma):\n",
    "    return np.exp(x*gamma)/(np.exp(x*gamma)+1)\n",
    "\n",
    "# * Define clock and target\n",
    "def init_clock_targ():\n",
    "    \n",
    "    lttb.y_targ_collection = []\n",
    "    \n",
    "    for k in range(n_contexts):\n",
    "        lttb.init_targ(par)\n",
    "        lttb.y_targ_collection.append(lttb.y_targ)\n",
    "    \n",
    "    \n",
    "    lttb.init_clock(par)\n",
    "\n",
    "# * -------------- TESTING FUNCTIONS --------------------\n",
    "def short_test(apicalFactor=0):\n",
    "    \n",
    "    mses = np.zeros(n_contexts)\n",
    "    \n",
    "    for cont_index in range(n_contexts):\n",
    "    \n",
    "        lttb.cont = lttb.cont*0\n",
    "        lttb.cont[cont_index] = 1\n",
    "        lttb.y_targ = lttb.y_targ_collection[cont_index]\n",
    "        lttb.initialize(par)\n",
    "    \n",
    "        #run simulation\n",
    "        for t in range(lttb.T-2):\n",
    "            lttb.step(apicalFactor)\n",
    "\n",
    "        SR = lttb.B_filt_total[:,1:-2]\n",
    "        Y = lttb.Jout@SR + np.tile(lttb.Bias,(lttb.T-3,1)).T\n",
    "        mse_rec_train = np.std(lttb.y_targ[:,1:-2] - Y)**2\n",
    "        mses[cont_index] = mse_rec_train\n",
    "    \n",
    "    return mses\n",
    "\n",
    "def full_test(apicalFactor=0):\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    stats['targs'] = []\n",
    "    stats['outputs'] = []\n",
    "    stats['contexts'] = []\n",
    "    stats['S_somas'] = []\n",
    "    stats['S_winds'] = []\n",
    "    stats['mses'] = np.zeros(n_contexts)\n",
    "    if n_contexts==2:\n",
    "        stats['mses_offDiag'] = np.zeros(n_contexts)\n",
    "    \n",
    "    for cont_index in range(n_contexts):\n",
    "        \n",
    "        context = np.zeros((lttb.T-2,n_contexts))\n",
    "        context[:,cont_index] = np.array([1 for _ in range(lttb.T-2)])\n",
    "        lttb.y_targ = lttb.y_targ_collection[cont_index]\n",
    "        lttb.initialize(par)\n",
    "\n",
    "        #run simulation\n",
    "        for t in range(lttb.T-2):\n",
    "            lttb.cont = context[t]\n",
    "            lttb.step(apicalFactor)\n",
    "\n",
    "        SR = lttb.B_filt_total[:,1:-2]\n",
    "        Y = lttb.Jout@SR + np.tile(lttb.Bias,(lttb.T-3,1)).T\n",
    "        \n",
    "        stats['outputs'].append(Y)\n",
    "        stats['contexts'].append(context)\n",
    "        stats['S_somas'].append(lttb.S_soma)\n",
    "        stats['S_winds'].append(lttb.S_wind)\n",
    "        stats['targs'].append(lttb.y_targ[:,1:-2])\n",
    "        stats['mses'][cont_index] = np.std(lttb.y_targ[:,1:-2] - Y)**2\n",
    "        if n_contexts==2:\n",
    "            wrong_targ = lttb.y_targ_collection[1-cont_index][:,1:-2]\n",
    "            stats['mses_offDiag'][cont_index] = np.std(wrong_targ - Y)**2\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# * --------------------- TRAINING FUNCTION --------------------------------\n",
    "def training(nIterRec=100, test_every=5, eta=5., eta_out=0.01, etaW=0., eta_bias=0.0002, \n",
    "             verbose = True):\n",
    "    \n",
    "    OUTER_ERRORS = np.zeros((int(nIterRec/test_every),n_contexts))\n",
    "    INNER_ERRORS = np.zeros((int(nIterRec/test_every),n_contexts))\n",
    "    \n",
    "    iterator = trange(nIterRec, desc = 'LTTB Training', leave = True)\n",
    "\n",
    "    for iteration in iterator:\n",
    "    \n",
    "        #initialize simulation\n",
    "        \n",
    "        for cont_index in range(n_contexts):\n",
    "        \n",
    "            lttb.cont = lttb.cont*0\n",
    "            lttb.cont[cont_index] = 1\n",
    "            lttb.y_targ = lttb.y_targ_collection[cont_index]\n",
    "            lttb.initialize(par)\n",
    "    \n",
    "            #run simulation\n",
    "            dH = 0\n",
    "            for t in range(lttb.T-2):\n",
    "                lttb.step(apicalFactor = 1)\n",
    "    \n",
    "                dH = dH*(1-dt/tau_m) + dt/tau_m*lttb.S_filt[:,t]\n",
    "                DJ = np.outer( ( lttb.S_apic_dist[:,t+1] - f(lttb.VapicRec[:,t],gamma) )*(1-lttb.S_apic_prox[:,t])*lttb.S_wind_soma[:,t+1] ,dH)\n",
    "                lttb.J =  lttb.J + eta*DJ\n",
    "                \n",
    "                if pin_Jrec:\n",
    "                    lttb.J[Ne:Ne+Ni,:] *= 0\n",
    "                    lttb.J[0:Ne,0:Ne] = np.maximum(0,lttb.J[0:Ne,0:Ne])\n",
    "                    lttb.J[0:Ne,0:Ne] = np.minimum(100,lttb.J[0:Ne,0:Ne])\n",
    "                    lttb.J[0:Ne,Ne:Ne+Ni] = np.minimum(0,lttb.J[0:Ne,Ne:Ne+Ni])\n",
    "                    lttb.J[0:Ne,Ne:Ne+Ni] = np.maximum(-100,lttb.J[0:Ne,Ne:Ne+Ni])\n",
    "                    np.fill_diagonal(lttb.J, 0.)\n",
    "    \n",
    "                SR = lttb.B_filt_total[:,t+1]\n",
    "                Y = lttb.Jout@SR + lttb.Bias\n",
    "                DJRO = np.outer(lttb.y_targ[:,t+1] - Y,SR.T)\n",
    "                dBias = lttb.y_targ[:,t+1] - Y\n",
    "                lttb.Jout = lttb.Jout + eta_out*DJRO\n",
    "                lttb.Bias = lttb.Bias + eta_bias*dBias\n",
    "        \n",
    "        ###### Test\n",
    "        \n",
    "        if (iteration+1)%test_every==0:\n",
    "            \n",
    "            INNER_ERRORS[int(iteration/test_every),:] = np.std(lttb.B_filt_rec-lttb.B_filt)**2\n",
    "            mses = short_test(apicalFactor = 0)\n",
    "            OUTER_ERRORS[int(iteration/test_every),:] = mses\n",
    "            \n",
    "            if verbose:\n",
    "                msg = 'LTTB Training. Outer MSEs: ' + ''.join([f'{mse:.4f} | ' for mse in mses])\n",
    "                iterator.set_description(msg)\n",
    "\n",
    "    return OUTER_ERRORS,INNER_ERRORS\n",
    "\n",
    "def render_fig_v1(dct):\n",
    "    \n",
    "    fs = 12\n",
    "    cm = 1/2.54  # centimeters in inches\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12*cm, 12*cm))\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fs, pad=1)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_linewidth(0.5)\n",
    "        ax.spines['bottom'].set_linewidth(0.5)\n",
    "        ax.xaxis.set_tick_params(width=0.5)\n",
    "        ax.yaxis.set_tick_params(width=0.5)\n",
    "    \n",
    "    ax = axes[0]\n",
    "    if (dct['par']['sigma_apical_cont']==0 and dct['par']['sigma_basal_cont']==0):\n",
    "        for d in range(dct['par']['n_contexts']):\n",
    "            ax.plot(0.*dct['par']['context'].T[d], zorder=1, ls='--', color=['black','red'][d], lw=1, alpha=0.5)\n",
    "    else:\n",
    "        for d in range(dct['par']['n_contexts']):\n",
    "            ax.plot(dct['par']['context'].T[d], zorder=1, ls='--', color=['black','red'][d], lw=1, alpha=0.5)\n",
    "    ax.set_ylabel('', fontsize=fs)\n",
    "    ax.set_xlim([0,1000])\n",
    "    ax.text(-0.15, 0.5, 'context', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "            transform=ax.transAxes, rotation_mode='anchor')\n",
    "        \n",
    "    ax = axes[1]\n",
    "    for d in range(dct['par']['O']):\n",
    "        ax.plot(dct['output'][0][d], zorder=0, ls='-', color='C' + str(d+1), lw=2)\n",
    "    for d in range(dct['par']['O']):\n",
    "        ax.plot(dct['target'][0][d], zorder=1, ls='--', color='C' + str(d+1), lw=1)\n",
    "    ax.set_ylabel('', fontsize=fs)\n",
    "    ax.set_xlim([0,1000])\n",
    "    ax.text(-0.15, 0.5, 'trajectories', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "            transform=ax.transAxes, rotation_mode='anchor')\n",
    "    \n",
    "    ax = axes[2]\n",
    "    ax.scatter(dct['spikes_idx'][1], dct['spikes_idx'][0], color='orange', marker='.', s=2)\n",
    "    ax.scatter(dct['bursts_idx'][1], dct['bursts_idx'][0], color='blue', marker='.', s=2)\n",
    "    ax.set_xlabel('t', fontsize=fs)\n",
    "    ax.set_ylabel('', fontsize=fs)\n",
    "    ax.set_xlim([0,1000])\n",
    "    ax.set_ylim([50,0])\n",
    "    ax.set_xticks([0,500,1000])\n",
    "    ax.set_yticks([50,25,0])\n",
    "    ax.text(-0.15, 0.5, 'neuron id', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "            transform=ax.transAxes, rotation_mode='anchor')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.tight_layout(pad=0.05, w_pad=0.5, h_pad=2.0)\n",
    "    plt.subplots_adjust(left=0.23, bottom=0.12, right=0.93, top=0.95, wspace=None, hspace=0.4)\n",
    "    for ext in ['pdf','eps','png']:\n",
    "        fig.savefig(\"./figures/Fig_1/Figure1_%s_v1.%s\" % (dct['session_name'],ext), transparent=False)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def render_fig_v2(dct):\n",
    "    \n",
    "    fs = 7\n",
    "    cm = 1/2.54  # centimeters in inches\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(6*cm, 6*cm))\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fs, pad=1)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['left'].set_linewidth(0.5)\n",
    "        ax.spines['bottom'].set_linewidth(0.5)\n",
    "        ax.xaxis.set_tick_params(width=0.5)\n",
    "        ax.yaxis.set_tick_params(width=0.5)\n",
    "    \n",
    "    ax = axes[0]\n",
    "    for d in range(dct['par']['O']):\n",
    "        ax.plot(dct['output'][0][d], zorder=0, ls='-', color='C' + str(d+1), lw=1)\n",
    "    for d in range(dct['par']['O']):\n",
    "        ax.plot(dct['target'][0][d], zorder=1, ls='--', color='C' + str(d+1), lw=0.5)\n",
    "    ax.set_ylabel('', fontsize=fs)\n",
    "    ax.set_xlim([0,1000])\n",
    "    ax.set_xticks([0,500,1000],[])\n",
    "    ax.text(-0.175, 0.5, 'trajectories', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "            transform=ax.transAxes, rotation_mode='anchor')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.scatter(dct['spikes_idx'][1], dct['spikes_idx'][0], color='orange', marker='.', s=1)\n",
    "    ax.scatter(dct['bursts_idx'][1], dct['bursts_idx'][0], color='blue', marker='.', s=1)\n",
    "    ax.set_xlabel('t', fontsize=fs)\n",
    "    ax.set_ylabel('', fontsize=fs)\n",
    "    ax.set_xlim([-0.5,1000.5])\n",
    "    ax.set_ylim([50.5,-0.5])\n",
    "    ax.set_xticks([0,500,1000])\n",
    "    ax.set_yticks([50,25,0])\n",
    "    ax.text(-0.175, 0.5, 'neuron id', fontsize=fs, ha='center', va='center', rotation=90, \\\n",
    "            transform=ax.transAxes, rotation_mode='anchor')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.tight_layout(pad=0.05, w_pad=0.5, h_pad=2.0)\n",
    "    plt.subplots_adjust(left=0.18, bottom=0.13, right=0.94, top=0.96, wspace=None, hspace=0.15)\n",
    "    for ext in ['pdf','eps','png']:\n",
    "        fig.savefig(\"./Figure1_%s_v2.%s\" % (dct['session_name'],ext), transparent=False, dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f48a72",
   "metadata": {},
   "source": [
    "### Model Initialization\n",
    "\n",
    "In this section we load the model parameters for this task (via the `json` configuration file) and then we inizialize the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e60863-02a1-4f97-9638-84866804843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./config.json', 'r') as fp:\n",
    "    par = json.load(fp)['FIGURE_1']\n",
    "\n",
    "n_contexts = par['n_contexts']\n",
    "T = par['T']\n",
    "dt = par['dt']\n",
    "tau_m = par['tau_m']\n",
    "eta = par['eta']\n",
    "eta_out = par['eta_out']\n",
    "eta_bias = par['eta_bias']\n",
    "Ne = par['Ne']\n",
    "Ni = par['Ni']\n",
    "gamma = 1./par['du']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab5a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lttb = lttb_module.LTTB(par)\n",
    "\n",
    "if True:\n",
    "    # generate new target\n",
    "    init_clock_targ()\n",
    "    Y_TARG_COLLECTION = []\n",
    "    for k in range(n_contexts):\n",
    "        Y_TARG_COLLECTION.append(lttb.y_targ_collection[k])\n",
    "    Y_TARG_COLLECTION = np.array(Y_TARG_COLLECTION)\n",
    "else:\n",
    "    # recall previous target\n",
    "    lttb.init_clock(par)\n",
    "    lttb.y_targ_collection = []\n",
    "    for k in range(n_contexts):\n",
    "        lttb.y_targ_collection.append(Y_TARG_COLLECTION[k])\n",
    "    lttb.y_targ_collection = np.array(lttb.y_targ_collection)\n",
    "\n",
    "if pin_Jrec:\n",
    "    lttb.J[Ne:Ne+Ni,:] *= 0\n",
    "    lttb.J[0:Ne,0:Ne] = np.maximum(0,lttb.J[0:Ne,0:Ne])\n",
    "    lttb.J[0:Ne,Ne:Ne+Ni] = np.minimum(0,lttb.J[0:Ne,Ne:Ne+Ni])\n",
    "    np.fill_diagonal(lttb.J, 0.)\n",
    "\n",
    "OUTER_ERRORS = []\n",
    "INNER_ERRORS = []\n",
    "\n",
    "nTotalEpochs = 0\n",
    "nIterRec = 50\n",
    "test_every = 5\n",
    "rescale_eta = True\n",
    "factor_eta = 0.99\n",
    "pin_Jrec = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1ba8a",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "In this section we train the model via the `training` function on the `3D Trajectory` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d69b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LTTB Training. MSEs: 0.1992 | : 100%|██████████| 100/100 [02:42<00:00,  1.63s/it]\n",
      "LTTB Training. MSEs: 0.1380 | : 100%|██████████| 100/100 [03:16<00:00,  1.97s/it]\n",
      "LTTB Training. MSEs: 0.1157 | : 100%|██████████| 100/100 [03:08<00:00,  1.89s/it]\n",
      "LTTB Training. MSEs: 0.0588 | : 100%|██████████| 100/100 [03:06<00:00,  1.87s/it]\n",
      "LTTB Training. MSEs: 0.0326 | : 100%|██████████| 100/100 [03:06<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 25\n",
    "nTotalEpochs += nEpochs\n",
    "\n",
    "for epoch in range(nEpochs):\n",
    "    outer_err,inner_err = training(nIterRec=nIterRec, test_every=test_every, \\\n",
    "                                   eta=eta, eta_out=eta_out, eta_bias=eta_bias, \\\n",
    "                                   verbose = True)\n",
    "    OUTER_ERRORS.extend(outer_err)\n",
    "    INNER_ERRORS.extend(inner_err)\n",
    "    if rescale_eta:\n",
    "        eta *= factor_eta\n",
    "        eta_out *= factor_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422e8ec-053f-405c-9f2d-9020453f7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1/2.54  # centimeters in inches\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20*cm, 8*cm))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot([l[0] for l in OUTER_ERRORS])\n",
    "ax.set_xlabel('training iterations (x5)')\n",
    "ax.set_ylabel('outer mse')\n",
    "ax.grid(True)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "plt.ylim([0,ymax])\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot([np.sqrt(l[0]) for l in INNER_ERRORS])\n",
    "ax.set_xlabel('training iterations (x5)')\n",
    "ax.set_ylabel('inner mse')\n",
    "ax.grid(True)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax.set_ylim([0,ymax])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=1.0, wspace=0.3, hspace=0)\n",
    "#fig.savefig(\"./mse_inner.eps\", transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6ca57c",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "\n",
    "In this section we perform a `full_test` of the model and collect the results for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6453a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = full_test(apicalFactor=1)\n",
    "\n",
    "cont_index = 0\n",
    "\n",
    "contexts = res['contexts']\n",
    "context = contexts[cont_index]\n",
    "Y = res['outputs'][cont_index]\n",
    "targ = res['targs'][cont_index]\n",
    "S_soma = res['S_somas'][cont_index]\n",
    "S_wind = res['S_winds'][cont_index]\n",
    "\n",
    "# first coordinate is for neurons\n",
    "# second coordinate is for time\n",
    "spikes_idx = np.where((S_wind==0) & (S_soma>0)) # spike somatici a finestra chiusa --> no burst\n",
    "bursts_idx = np.where((S_wind>0) & (S_soma>0)) # spike somatici a finestra aperta --> burst\n",
    "\n",
    "#L1 = list(zip(spikes_idx[0],spikes_idx[1]))\n",
    "#L2 = list(zip(bursts_idx[0],bursts_idx[1]))\n",
    "#L1f = [tup for tup in L1 if (tup[0]>2 and tup[0]<49)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee537a68",
   "metadata": {},
   "source": [
    "### Save/Load and Visualize Results\n",
    "\n",
    "In this section we save/load the results and compose the final visualization used in `Figure_1` of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load = False\n",
    "\n",
    "if not Load:\n",
    "    \n",
    "    # SAVING\n",
    "    \n",
    "    dct = {}\n",
    "    dct['session_name'] = 'n02_TeachON_TrainON_fixedJ'\n",
    "    dct['par'] = par\n",
    "    dct['par']['N_epochs'] = nTotalEpochs\n",
    "    dct['par']['N_iterEpoch'] = nIterRec\n",
    "    dct['par']['test_every'] = test_every\n",
    "    dct['par']['rescale_eta'] = rescale_eta\n",
    "    dct['par']['factor_eta'] = factor_eta\n",
    "    dct['par']['pin_Jrec'] = pin_Jrec\n",
    "    dct['target'] = [_ for _ in lttb.y_targ_collection]\n",
    "    dct['contexts'] = [_.tolist() for _ in contexts]\n",
    "    dct['output'] = [_ for _ in res['outputs']]\n",
    "    for i,ii in enumerate(dct['target']):\n",
    "        dct['target'][i] = [_ for _ in dct['target'][i]]\n",
    "        for j,jj in enumerate(dct['target'][i]):\n",
    "            dct['target'][i][j] = [round(_,8) for _ in dct['target'][i][j]]\n",
    "    for i,ii in enumerate(dct['output']):\n",
    "        dct['output'][i] = [_ for _ in dct['output'][i]]\n",
    "        for j,jj in enumerate(dct['output'][i]):\n",
    "            dct['output'][i][j] = [round(_,8) for _ in dct['output'][i][j]]\n",
    "    dct['outer_mse_during_training'] = [[_ for _ in l] for l in OUTER_ERRORS] # [round(l[0],8) for l in OUTER_ERRORS]\n",
    "    dct['inner_mse_during_training'] = [[_ for _ in l] for l in INNER_ERRORS] # [round(l[0],8) for l in INNER_ERRORS]\n",
    "    dct['spikes_idx'] = [spikes_idx[0].tolist(),spikes_idx[1].tolist()]\n",
    "    dct['bursts_idx'] = [bursts_idx[0].tolist(),bursts_idx[1].tolist()]\n",
    "    \n",
    "    with open ('./data/Fig_1/Figure1_%s.json' % dct['session_name'], 'w') as fp:\n",
    "        json.dump(dct, fp)\n",
    "    \n",
    "    render_fig_v2(dct)\n",
    "\n",
    "else:\n",
    "    \n",
    "    # LOADING\n",
    "    \n",
    "    session_name = '01_noTeach'\n",
    "    \n",
    "    with open ('./Figure1_n%s.json' % session_name) as fp:\n",
    "        dct = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195a575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccc938d5-4eef-4eb3-9d22-e18beca09f91",
   "metadata": {},
   "source": [
    "### Many-sample averages\n",
    "\n",
    "In this section we average over many samples the results for `Figure_1` of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfbd30b-8251-4908-a735-e2e71722ee77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "files_TeachON = glob.glob('./data/Fig_1/Figure1_n??_TeachON_TrainON.json')\n",
    "files_TeachON.sort()\n",
    "print(files_TeachON)\n",
    "fs_TeachON = []\n",
    "for file in files_TeachON:\n",
    "    with open (file) as fp:\n",
    "        ff = json.load(fp)\n",
    "        fs_TeachON.append(ff)\n",
    "\n",
    "files_TeachOFF = glob.glob('./data/Fig_1/Figure1_n??_TeachOFF_TrainON.json')\n",
    "files_TeachOFF.sort()\n",
    "print(files_TeachOFF)\n",
    "fs_TeachOFF = []\n",
    "for file in files_TeachOFF:\n",
    "    with open (file) as fp:\n",
    "        ff = json.load(fp)\n",
    "        fs_TeachOFF.append(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0805c-e858-41f1-90a5-51f6c4cb025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8*cm, 6*cm))\n",
    "\n",
    "Y = []\n",
    "for ff,fff in enumerate(fs_TeachOFF):\n",
    "    y = [_[0] for _ in fff['outer_mse_during_training']]\n",
    "    Y.append(np.array(y))\n",
    "    #plt.plot(y, label=None, lw=0.75, color='grey')\n",
    "Y = np.array(Y)\n",
    "M = np.mean(Y,axis=0)\n",
    "S = np.std(Y,axis=0)\n",
    "plt.fill_between(range(len(M)), M-S, M+S, alpha=0.3, color='C0')\n",
    "plt.plot(M, label=None, lw=2, color='C0')\n",
    "\n",
    "Y = []\n",
    "for ff,fff in enumerate(fs_TeachOFF):\n",
    "    y = [100000*_[0] for _ in fff['inner_mse_during_training']]\n",
    "    Y.append(np.array(y))\n",
    "    #plt.plot(y, label=None, lw=0.75, color='grey')\n",
    "Y = np.array(Y)\n",
    "M = np.mean(Y,axis=0)\n",
    "S = np.std(Y,axis=0)\n",
    "plt.fill_between(range(len(M)), M-S, M+S, alpha=0.3, color='C1')\n",
    "plt.plot(M, label=None, lw=2, color='C1')\n",
    "\n",
    "#plt.plot([0,200],[0.05,0.05],color='black',lw=2,ls='--')\n",
    "plt.xlim([0,200])\n",
    "plt.ylim([0.01,1])\n",
    "plt.yscale('log')\n",
    "plt.xlabel('training iterations (x5)')\n",
    "plt.ylabel('outer mse')\n",
    "plt.grid(True)\n",
    "ymin, ymax = plt.gca().get_ylim()\n",
    "#plt.ylim([0,ymax])\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.tight_layout(pad=0.05, w_pad=0.5, h_pad=2.0)\n",
    "plt.subplots_adjust(left=0.22, bottom=0.20, right=0.96, top=0.96, wspace=None, hspace=0.15)\n",
    "for ext in ['pdf','eps','png']:\n",
    "    fig.savefig(\"./figures/Fig_1/Figure1_mean_outer_mse_TeachON.%s\" % ext, transparent=False, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
